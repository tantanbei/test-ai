{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "914cb99e-cb87-42d5-ba3c-bc4935737a95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提前还款后，期数减少和每期还款金额减少，哪个更好?\n",
      "嗯，我现在在考虑一个关于提前还款的问题。假设我有一笔贷款，比如一张信用卡或者银行的贷款，还贷的时候，如果提前还款的话，可能会有两种结果：期数减少和每期还款金额减少。那么，这两种情况哪个更好呢？这个问题看起来有点复杂，但我觉得我可以慢慢理清楚。\n",
      "\n",
      "首先，我需要明确什么是提前还款。提前还款就是说，我提前支付了部分或全部还款额，这样可能会让贷款的剩余本金减少，从而减少剩余的利息，同时可能还清部分本金，甚至提前还清贷款。这样一来，贷款的期数也会减少，因为还款的时间缩短了。\n",
      "\n",
      "那么，期数减少和每期还款金额减少，哪个更好呢？我觉得这取决于两种因素：一是提前还款后，剩余的本金减少了多少，从而减少了利息；二是提前还款后，我需要支付的总还款金额是否比只还款完贷款的时间更少，或者更少。\n",
      "\n",
      "首先，我应该考虑的是期数减少。如果提前还款，贷款的剩余本金减少，利息也会减少，因为利息是基于本金计算的，而本金减少了，所以利息自然也会减少。这样，还款的时间就会缩短，意味着我只需要偿还一次本金，甚至可能在更短的时间内还清贷款。这样看起来，期数减少应该是更优的选择。\n",
      "\n",
      "但是，另一方面，如果我只支付了部分还款，那么剩余的本金减少，但每期还款的金额也会减少，因为利息已经减少，所以每期还款的金额可能也会减少。这样看起来，每期还款金额减少也是个好的选择。\n",
      "\n",
      "那么，这两种情况哪个更好呢？我觉得这取决于我想要什么。如果我想要提前还清贷款，而不想增加额外的还款负担，可能期数减少更优。但如果我想要每期还款金额减少，可能更愿意接受更多的本金减少，这样每期还款金额减少，同时期数也减少，可能更划算。\n",
      "\n",
      "不过，我需要考虑的是，提前还款的总还款金额是否真的比只还款完贷款的时间更少。比如说，假设贷款本金是10000元，年利率是5%，期限是10年。如果我提前还款，比如说在5年的时候，我只还了5000元，那么剩下的5000元需要在剩下的5年里偿还。这时候，每期还款金额可能会减少，但同时我只需要偿还一次本金，可能比只还完贷款的时间更少。\n",
      "\n",
      "不过，我可能需要计算一下，提前还款后，总还款金额和期数的变化情况。比如，假设我提前还款，只还了部分本金，那么剩余的本金减少，利息减少，所以每期还款金额减少，同时期数也减少，因为剩下的本金减少，利息也减少了，所以还款的总时间也减少了。\n",
      "\n",
      "但是，我需要考虑的是，提前还款后的利息是否真的比不提前还款的利息少了。比如说，如果我不提前还款，每期还款金额会比较高，而如果提前还款，虽然每期还款金额减少，但总还款金额可能比只还完贷款的时间更少，因为利息减少了。\n",
      "\n",
      "或者，可能更准确的是，提前还款后，总还款金额减少，因为利息减少了，而期数也减少，因为剩余的本金减少了。所以，两种情况都是好的，但可能需要权衡一下，哪种更划算。\n",
      "\n",
      "不过，我可能有点混淆了。提前还款后，我只需要偿还一次本金，而如果只还完贷款的时间更少，可能意味着我只需要偿还一次本金，而不需要偿还更多的本金，这样可能更划算。\n",
      "\n",
      "或者，我应该考虑的是，提前还款后，剩下的本金减少，利息减少，所以每期还款金额减少，同时期数减少，这样可能更划算，因为总还款金额减少，而且期数也减少，可能更少。\n",
      "\n",
      "不过，我可能需要更详细地计算一下。假设贷款本金是P，年利率是r，期限是n期，那么每月还款金额可以用公式计算：\n",
      "\n",
      "E = P * (r*(1+r)^n) / ((1+r)^n - 1)\n",
      "\n",
      "如果提前还款，比如说在k期的时候，我只还了部分本金，那么剩下的本金减少，利息减少，所以每期还款金额减少，同时期数减少，因为剩下的本金减少了，利息也减少了，所以还款的总时间更短。\n",
      "\n",
      "但是，我可能需要考虑的是，提前还款后，我是否真的只需要偿还一次本金，而不需要偿还剩下的本金。比如说，如果我提前还款了全部本金，那么剩下的本金是零，这样可能更划算，因为不需要偿还任何利息。\n",
      "\n",
      "不过，这可能取决于贷款的结构，比如信用卡的利息计算方式是否是按月计算，还是按年计算。如果是按月计算的话，提前还款后\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "\n",
    "c = \"提前还款后，期数减少和每期还款金额减少，哪个更好?\"\n",
    "print(c)\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": c}\n",
    "]\n",
    "input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "\n",
    "# 创建 attention_mask\n",
    "#attention_mask = torch.ones_like(input_tensor)\n",
    "\n",
    "outputs = model.generate(input_tensor.to(model.device), max_new_tokens=1000)\n",
    "\n",
    "result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5b438d2-a539-4ff1-885c-23b2e82a98e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\n",
      "</think>\n",
      "\n",
      "Greetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GenerationConfig\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16)\n",
    "model.generation_config = GenerationConfig.from_pretrained(model_name)\n",
    "model.generation_config.pad_token_id = model.generation_config.eos_token_id\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"}\n",
    "]\n",
    "input_tensor = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "outputs = model.generate(input_tensor.to(model.device), max_new_tokens=100)\n",
    "\n",
    "result = tokenizer.decode(outputs[0][input_tensor.shape[1]:], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb563940-57c0-4c93-a133-94c7ffd8cabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
